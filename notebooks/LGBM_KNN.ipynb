{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZYYxo-jJKFi",
        "outputId": "7ba23dfb-8bd5-4a78-b241-51d760454a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFeAqP9DrHP5"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def customer_hex_id_to_int(series):\n",
        "    return series.str[-16:].apply(hex_id_to_int)\n",
        "\n",
        "def hex_id_to_int(str):\n",
        "    return int(str[-16:], 16)\n",
        "\n",
        "def article_id_str_to_int(series):\n",
        "    return series.astype('int32')\n",
        "\n",
        "def article_id_int_to_str(series):\n",
        "    return '0' + series.astype('str')\n",
        "\n",
        "class Categorize(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, min_examples=0):\n",
        "        self.min_examples = min_examples\n",
        "        self.categories = []\n",
        "\n",
        "    def fit(self, X):\n",
        "        for i in range(X.shape[1]):\n",
        "            vc = X.iloc[:, i].value_counts()\n",
        "            self.categories.append(vc[vc > self.min_examples].index.tolist())\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        data = {X.columns[i]: pd.Categorical(X.iloc[:, i], categories=self.categories[i]).codes for i in range(X.shape[1])}\n",
        "        return pd.DataFrame(data=data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_parquet(\"/content/drive/MyDrive/CS 7641 Machine Learning Group Project/lgbmknndata.parquet\")"
      ],
      "metadata": {
        "id": "03JmxiQorqXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from lightgbm.sklearn import LGBMRanker\n",
        "\n",
        "def customer_hex_id_to_int(series):\n",
        "    return series.str[-16:].apply(hex_id_to_int)\n",
        "\n",
        "def hex_id_to_int(str):\n",
        "    return int(str[-16:], 16)\n",
        "\n",
        "def article_id_str_to_int(series):\n",
        "    return series.astype('int32')\n",
        "\n",
        "def article_id_int_to_str(series):\n",
        "    return '0' + series.astype('str')\n",
        "\n",
        "class Categorize(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, min_examples=0):\n",
        "        self.min_examples = min_examples\n",
        "        self.categories = []\n",
        "\n",
        "    def fit(self, X):\n",
        "        for i in range(X.shape[1]):\n",
        "            vc = X.iloc[:, i].value_counts()\n",
        "            self.categories.append(vc[vc > self.min_examples].index.tolist())\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        data = {X.columns[i]: pd.Categorical(X.iloc[:, i], categories=self.categories[i]).codes for i in range(X.shape[1])}\n",
        "        return pd.DataFrame(data=data)\n",
        "\n",
        "data = pd.read_parquet(\"/content/drive/MyDrive/CS 7641 Machine Learning Group Project/lgbmknndata.parquet\")\n",
        "# data = pd.read_parquet(\"lgbmknndata.parquet\")\n",
        "\n",
        "train = data[(data.week != 104) & (data.week != 105)]\n",
        "test = data[data.week==104].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()\n",
        "\n",
        "train_baskets = train.groupby(['week', 'customer_id'])['article_id'].count().values\n",
        "\n",
        "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
        "'perceived_colour_master_id', 'department_no', 'index_code',\n",
        "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
        "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'bestseller_rank']\n",
        "\n",
        "train_X = train[columns_to_use]\n",
        "train_y = train['purchased']\n",
        "\n",
        "neighbors1 = KNeighborsClassifier(n_neighbors=3)\n",
        "neighbors1 = neighbors1.fit(\n",
        "    train_X,\n",
        "    train_y,\n",
        ")\n",
        "\n",
        "ranker = LGBMRanker(\n",
        "    objective=\"lambdarank\",\n",
        "    metric=\"ndcg\",\n",
        "    boosting_type=\"dart\",\n",
        "    n_estimators=1,\n",
        "    importance_type='gain',\n",
        "    learning_rate=0.03,\n",
        "    verbose=10\n",
        ")\n",
        "ranker = ranker.fit(\n",
        "    train_X,\n",
        "    train_y,\n",
        "    group=train_baskets,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "for i in ranker.feature_importances_.argsort()[::-1]:\n",
        "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlRnoABoww8X",
        "outputId": "6ad3595b-68e2-435a-f85b-8c27c048a3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.797727\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.120156\n",
            "[LightGBM] [Debug] init for col-wise cost 0.172728 seconds, init for row-wise cost 1.025744 seconds\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.619236 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
            "[LightGBM] [Info] Total Bins 1138\n",
            "[LightGBM] [Info] Number of data points in the train set: 4844840, number of used features: 18\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
            "bestseller_rank 0.9991608123407203\n",
            "age 0.00027114816482595445\n",
            "garment_group_no 0.0001618962712558173\n",
            "article_id 0.00010371299962208835\n",
            "Active 5.480771028614211e-05\n",
            "department_no 4.870119202285968e-05\n",
            "postal_code 4.562004276840647e-05\n",
            "colour_group_code 3.5326514992692575e-05\n",
            "product_type_no 3.493293493563135e-05\n",
            "perceived_colour_value_id 3.0913530344193644e-05\n",
            "graphical_appearance_no 2.6247246200984754e-05\n",
            "club_member_status 2.588105202489576e-05\n",
            "FN 0.0\n",
            "fashion_news_frequency 0.0\n",
            "index_group_no 0.0\n",
            "section_no 0.0\n",
            "perceived_colour_master_id 0.0\n",
            "index_code 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test KNN and LGBM\n",
        "directory = '/content/drive/MyDrive/CS 7641 Machine Learning Group Project/'\n",
        "testfiles = ['test1.csv', 'test2.csv', 'test3.csv', 'test4.csv', 'test5.csv', 'test6.csv']\n",
        "for testf in testfiles:\n",
        "    print(\"predicitng for testf\", directory+testf)\n",
        "    cust_to_pred = pd.read_csv(directory+testf)\n",
        "    changedpred = cust_to_pred\n",
        "    changedpred['customer_id'] = customer_hex_id_to_int(changedpred['customer_id'])\n",
        "\n",
        "    testdata = test[test[\"customer_id\"].isin(changedpred[\"customer_id\"])]\n",
        "\n",
        "    test_X = testdata[columns_to_use]\n",
        "\n",
        "    knnpred = testdata.copy()\n",
        "\n",
        "    testdata['preds'] = ranker.predict(test_X)\n",
        "\n",
        "    knnpred['preds'] = neighbors1.predict_proba(test_X)[:,1]\n",
        "\n",
        "    c_id2predicted_article_ids1 = testdata \\\n",
        "        .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
        "        .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
        "\n",
        "    c_id2predicted_article_ids2 = knnpred \\\n",
        "        .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
        "        .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
        "\n",
        "    bestsellinglastweekdf = data[data.week == 103]\n",
        "    bestsellinglastweek = bestsellinglastweekdf['article_id'].value_counts().head(12)\n",
        "\n",
        "    cust_to_pred = pd.read_csv(directory+testf)\n",
        "    customers = cust_to_pred[['customer_id']].drop_duplicates()\n",
        "    customers['prediction'] = 1\n",
        "\n",
        "    bestsellinglastweek = bestsellinglastweek.index.tolist()\n",
        "\n",
        "    preds = []\n",
        "    for c_id in customer_hex_id_to_int(customers.customer_id):\n",
        "        pred = c_id2predicted_article_ids1.get(c_id, [])\n",
        "        pred = pred + bestsellinglastweek\n",
        "        preds.append(pred[:12])\n",
        "\n",
        "    predsknn = []\n",
        "    for c_id in customer_hex_id_to_int(customers.customer_id):\n",
        "        pred = c_id2predicted_article_ids2.get(c_id, [])\n",
        "        pred = pred + bestsellinglastweek\n",
        "        predsknn.append(pred[:12])\n",
        "\n",
        "    knncustomers = customers.copy()\n",
        "\n",
        "    preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
        "    customers.prediction = preds\n",
        "\n",
        "    predsknn = [' '.join(['0' + str(p) for p in ps]) for ps in predsknn]\n",
        "    knncustomers.prediction = predsknn\n",
        "\n",
        "    customers.to_csv(directory+'lgbm_submission_'+testf, index=False)\n",
        "    knncustomers.to_csv(directory+'knn_submission_'+testf, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU4yMT1Iw2wH",
        "outputId": "ec0f3be8-bb27-40ab-82f7-8bbaae7f2907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicitng for testf /content/drive/MyDrive/CS 7641 Machine Learning Group Project/test1.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-a185a9185d66>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testdata['preds'] = ranker.predict(test_X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicitng for testf /content/drive/MyDrive/CS 7641 Machine Learning Group Project/test2.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-a185a9185d66>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testdata['preds'] = ranker.predict(test_X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicitng for testf /content/drive/MyDrive/CS 7641 Machine Learning Group Project/test3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-a185a9185d66>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testdata['preds'] = ranker.predict(test_X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicitng for testf /content/drive/MyDrive/CS 7641 Machine Learning Group Project/test4.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-a185a9185d66>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testdata['preds'] = ranker.predict(test_X)\n"
          ]
        }
      ]
    }
  ]
}